{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:13:30.852979568Z",
     "start_time": "2023-05-12T09:13:30.834036804Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.chdir(\"/tf/notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:13:35.073499407Z",
     "start_time": "2023-05-12T09:13:30.852905838Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import optimizers, callbacks\n",
    "\n",
    "from models import SiameseModel, init_network\n",
    "from utils import load_data, visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:13:35.081485455Z",
     "start_time": "2023-05-12T09:13:35.078975494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.12.0\n",
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 09:13:35.077423: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:12:00.671878714Z",
     "start_time": "2023-05-12T09:11:59.544637152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6194 files belonging to 1 classes.\n",
      "Found 6194 files belonging to 1 classes.\n",
      "Found 6194 files belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run ShuffleDatasetV3: Could not synchronize CUDA stream: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure [Op:ShuffleDatasetV3]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m BATCH_SIZE \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m16\u001B[39m\n\u001B[0;32m----> 2\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[43mload_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43manchor_images_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/tf/CVUSA/terrestrial\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mpositive_images_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/tf/CVUSA/satellite\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m visualise(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(train_data\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mas_numpy_iterator())[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m/tf/notebooks/utils.py:48\u001B[0m, in \u001B[0;36mload_data\u001B[0;34m(anchor_images_path, positive_images_path, input_shape, batch_size)\u001B[0m\n\u001B[1;32m     34\u001B[0m anchor_dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mimage_dataset_from_directory(anchor_images_path,\n\u001B[1;32m     35\u001B[0m                                                              label_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     36\u001B[0m                                                              color_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrgb\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     37\u001B[0m                                                              image_size\u001B[38;5;241m=\u001B[39minput_shape,\n\u001B[1;32m     38\u001B[0m                                                              batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m     39\u001B[0m                                                              shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     41\u001B[0m positive_dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mimage_dataset_from_directory(positive_images_path,\n\u001B[1;32m     42\u001B[0m                                                                label_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     43\u001B[0m                                                                color_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrgb\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     44\u001B[0m                                                                image_size\u001B[38;5;241m=\u001B[39minput_shape,\n\u001B[1;32m     45\u001B[0m                                                                batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m     46\u001B[0m                                                                shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 48\u001B[0m negative_dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mimage_dataset_from_directory(positive_images_path,\n\u001B[1;32m     49\u001B[0m                                                                label_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     50\u001B[0m                                                                color_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrgb\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     51\u001B[0m                                                                image_size\u001B[38;5;241m=\u001B[39minput_shape,\n\u001B[1;32m     52\u001B[0m                                                                batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m     53\u001B[0m                                                                shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     54\u001B[0m                                                                seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m     55\u001B[0m negative_dataset \u001B[38;5;241m=\u001B[39m negative_dataset\u001B[38;5;241m.\u001B[39mshuffle(buffer_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m, reshuffle_each_iteration\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     57\u001B[0m dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mzip((anchor_dataset, positive_dataset, negative_dataset))\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/image_dataset.py:316\u001B[0m, in \u001B[0;36mimage_dataset_from_directory\u001B[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001B[0m\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[1;32m    315\u001B[0m         \u001B[38;5;66;03m# Shuffle locally at each iteration\u001B[39;00m\n\u001B[0;32m--> 316\u001B[0m         dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    317\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mbatch(batch_size)\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1448\u001B[0m, in \u001B[0;36mDatasetV2.shuffle\u001B[0;34m(self, buffer_size, seed, reshuffle_each_iteration, name)\u001B[0m\n\u001B[1;32m   1379\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshuffle\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1380\u001B[0m             buffer_size,\n\u001B[1;32m   1381\u001B[0m             seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1382\u001B[0m             reshuffle_each_iteration\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1383\u001B[0m             name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1384\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Randomly shuffles the elements of this dataset.\u001B[39;00m\n\u001B[1;32m   1385\u001B[0m \n\u001B[1;32m   1386\u001B[0m \u001B[38;5;124;03m  This dataset fills a buffer with `buffer_size` elements, then randomly\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1446\u001B[0m \u001B[38;5;124;03m    A new `Dataset` with the transformation applied as described above.\u001B[39;00m\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1448\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mshuffle_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_shuffle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m   1449\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreshuffle_each_iteration\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/shuffle_op.py:31\u001B[0m, in \u001B[0;36m_shuffle\u001B[0;34m(input_dataset, buffer_size, seed, reshuffle_each_iteration, name)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_shuffle\u001B[39m(  \u001B[38;5;66;03m# pylint: disable=unused-private-name\u001B[39;00m\n\u001B[1;32m     26\u001B[0m     input_dataset,\n\u001B[1;32m     27\u001B[0m     buffer_size,\n\u001B[1;32m     28\u001B[0m     seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     29\u001B[0m     reshuffle_each_iteration\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     30\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 31\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_ShuffleDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m      \u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreshuffle_each_iteration\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/shuffle_op.py:56\u001B[0m, in \u001B[0;36m_ShuffleDataset.__init__\u001B[0;34m(self, input_dataset, buffer_size, seed, reshuffle_each_iteration, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m=\u001B[39m name\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (tf2\u001B[38;5;241m.\u001B[39menabled() \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m     55\u001B[0m     (context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mor\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minside_function())):\n\u001B[0;32m---> 56\u001B[0m   variant_tensor \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshuffle_dataset_v3\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[43m      \u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variant_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m     58\u001B[0m \u001B[43m      \u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m      \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m      \u001B[49m\u001B[43mseed2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_seed2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m      \u001B[49m\u001B[43mseed_generator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdummy_seed_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[43m      \u001B[49m\u001B[43mreshuffle_each_iteration\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reshuffle_each_iteration\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_common_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     65\u001B[0m   variant_tensor \u001B[38;5;241m=\u001B[39m gen_dataset_ops\u001B[38;5;241m.\u001B[39mshuffle_dataset(\n\u001B[1;32m     66\u001B[0m       input_dataset\u001B[38;5;241m.\u001B[39m_variant_tensor,  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m     67\u001B[0m       buffer_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer_size,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m       reshuffle_each_iteration\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reshuffle_each_iteration,\n\u001B[1;32m     71\u001B[0m       \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_common_args)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py:7105\u001B[0m, in \u001B[0;36mshuffle_dataset_v3\u001B[0;34m(input_dataset, buffer_size, seed, seed2, seed_generator, output_types, output_shapes, reshuffle_each_iteration, metadata, name)\u001B[0m\n\u001B[1;32m   7103\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   7104\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 7105\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   7106\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[1;32m   7107\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:7262\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   7260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[1;32m   7261\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 7262\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "\u001B[0;31mInternalError\u001B[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run ShuffleDatasetV3: Could not synchronize CUDA stream: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure [Op:ShuffleDatasetV3]"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_data = load_data(anchor_images_path=\"/tf/CVUSA/terrestrial\",\n",
    "                       positive_images_path=\"/tf/CVUSA/satellite\",\n",
    "                       batch_size=BATCH_SIZE)\n",
    "visualise(*list(train_data.take(1).as_numpy_iterator())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T12:57:09.926413994Z",
     "start_time": "2023-05-11T12:57:08.313597318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checkpoint during training\n",
    "model = SiameseModel()\n",
    "model.compile(optimizer=optimizers.Adam(0.001),\n",
    "              weighted_metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T12:58:49.445829258Z",
     "start_time": "2023-05-11T12:57:09.927283879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 99s 202ms/step - loss: 0.9078\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7faa2ef91d90>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,\n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T10:07:05.664934136Z",
     "start_time": "2023-05-11T10:06:53.656840668Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tf/notebooks/resnet/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tf/notebooks/resnet/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model.siamese_network, \"/tf/notebooks/resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tf/notebooks/resnet_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tf/notebooks/resnet_2/assets\n"
     ]
    }
   ],
   "source": [
    "model.siamese_network.save(\"/tf/notebooks/resnet_2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T10:10:02.608717292Z",
     "start_time": "2023-05-11T10:09:50.430800256Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 95s 216ms/step - loss: 0.5004\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7ff544b20340>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_2 = init_network()\n",
    "network_2.load_weights(\"/tf/notebooks/resnet_2\")\n",
    "model_2 = SiameseModel(network_2)\n",
    "model_2.compile(optimizer=optimizers.Adam(0.001), weighted_metrics=[])\n",
    "model_2.fit(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T10:13:49.474083955Z",
     "start_time": "2023-05-11T10:12:12.756636115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T10:07:36.303117890Z",
     "start_time": "2023-05-11T10:07:32.298517202Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T10:07:44.840571184Z",
     "start_time": "2023-05-11T10:07:44.831833342Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
